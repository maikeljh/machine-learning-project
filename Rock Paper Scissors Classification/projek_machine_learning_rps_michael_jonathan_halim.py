# -*- coding: utf-8 -*-
"""Projek_Machine_Learning_RPS_Michael_Jonathan_Halim.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14C5NQizvs63Iejkb_udDgzJfyVo0X0fi
"""

# Men-download Dataset Untuk Projek ML Rock Paper Scissors dari URL yang disediakan
!wget https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip

# Meng-impor library TensorFlow
import tensorflow as tf
print(tf.__version__)

# Meng-extract zip file dataset Rock Paper Scissors ke dalam folder ProjekML
import zipfile,os
local_zip = 'rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('ProjekML')
zip_ref.close()

# Membuat Directory untuk Train dan Validation Dataset
base_dir = 'ProjekML/rockpaperscissors'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'val')

os.mkdir(train_dir)
os.mkdir(validation_dir)

os.listdir(base_dir)

paper_direc = os.path.join(base_dir, 'paper')
rock_direc = os.path.join(base_dir,'rock')
scissors_direc = os.path.join(base_dir,'scissors')

train_paper = os.path.join(train_dir, 'paper')
train_rock = os.path.join(train_dir, 'rock')
train_scissors = os.path.join(train_dir, 'scissors')

os.mkdir(train_paper)
os.mkdir(train_rock)
os.mkdir(train_scissors)

validation_paper = os.path.join(validation_dir, 'paper')
validation_rock = os.path.join(validation_dir, 'rock')
validation_scissors = os.path.join(validation_dir, 'scissors')

os.mkdir(validation_paper)
os.mkdir(validation_rock)
os.mkdir(validation_scissors)

# Meng-import train and test split library dari sklearn
from sklearn.model_selection import train_test_split

# Memanggil fungsi train_test_split untuk split train dan validation dataset (Memisahkan directory paper, rock, dan scissors menjadi data train 60% dan data validation 40%)
train_paper_dir, validation_paper_dir = train_test_split(os.listdir(paper_direc), test_size = 0.40)
train_rock_dir, validation_rock_dir = train_test_split(os.listdir(rock_direc), test_size = 0.40)
train_scissors_dir, validation_scissors_dir = train_test_split(os.listdir(scissors_direc), test_size = 0.40)

# Meng-import library shutil untuk copy files ke dalam directory train dan validation
import shutil

# Meng-copy dataset
for file in train_paper_dir:
  shutil.copy(os.path.join(paper_direc, file), os.path.join(train_paper, file))
for file in train_rock_dir:
  shutil.copy(os.path.join(rock_direc,file), os.path.join(train_rock,file))
for file in train_scissors_dir:
  shutil.copy(os.path.join(scissors_direc,file), os.path.join(train_scissors,file))
for file in validation_paper_dir:
  shutil.copy(os.path.join(paper_direc, file), os.path.join(validation_paper,file))
for file in validation_rock_dir:
  shutil.copy(os.path.join(rock_direc,file), os.path.join(validation_rock,file))
for file in validation_scissors_dir:
  shutil.copy(os.path.join(scissors_direc,file), os.path.join(validation_scissors,file))

# Membuat Proses Augmentasi Gambar dengan fungsi ImageDataGenerator()
from tensorflow.keras.preprocessing.image import ImageDataGenerator
     
train_datagen = ImageDataGenerator(
                        rescale=1./255,
                        rotation_range=20,
                        horizontal_flip=True,
                        shear_range = 0.2,
                        fill_mode = 'nearest')
     
test_datagen = ImageDataGenerator(
                        rescale=1./255,
                        rotation_range=20,
                        vertical_flip = True,
                        horizontal_flip=True,
                        shear_range = 0.2,
                        fill_mode = 'nearest')

# Mempersiapkan data train dan data validation untuk dipelajari oleh model
train_generator = train_datagen.flow_from_directory(
        train_dir,  # Directory data train
        target_size = (150, 150),  # Mengubah resolusi semua gambar menjadi 150x150 pixel
        batch_size = 32,
        # Karena masalah klasifikasi 3 kelas maka menggunakan class_mode = 'categorical'
        class_mode = 'categorical')
     
validation_generator = test_datagen.flow_from_directory(
        validation_dir, # Directory data validation
        target_size = (150, 150), # Mengubah resolusi semua gambar menjadi 150x150 pixel
        batch_size = 32, # Karena masalah klasifikasi 3 kelas maka menggunakan class_mode = 'categorical'
        class_mode = 'categorical')

# Membangun arsitektur sebuah CNN
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])

# Meng-compile model dengan 'adam' optimizer loss function 'categorical_crossentropy' 
model.compile(loss='categorical_crossentropy',
              optimizer=tf.optimizers.Adam(),
              metrics=['accuracy'])

# Jangan lupa menggunakan method Callback untuk stop latih model ketika akurasi sudah menyentuh 97% (Dipelajari dari Website TensorFlow)
class FitCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') > 0.97):
      self.model.stop_training = True

callbacks = FitCallback()

# latih model dengan model.fit 
model.fit(
      train_generator,
      # Karena ada 1312 images untuk train, maka steps_per_epoch = images / batch_size = 1312 / 32 = 41
      steps_per_epoch = 41,  # berapa batch yang akan dieksekusi pada setiap epoch
      epochs = 20, # tambahkan eposchs jika akurasi model belum optimal
      validation_data = validation_generator, # menampilkan akurasi pengujian data validasi
      # Karena ada 876 images untuk validation, maka validation_steps = images / batch_size = 876 / 32 = sekitar 27
      validation_steps = 27,  # berapa batch yang akan dieksekusi pada setiap epoch
      verbose = 2,
      # Masukkan method callback untuk stop latih model ketika menyentuh target akurasi yaitu 97%
        callbacks = [FitCallback()]
      )

# Commented out IPython magic to ensure Python compatibility.
# Me-resize gambar yang diupload dan diubah menjadi larik numpy
import numpy as np
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline
     
uploaded = files.upload()
     
for fn in uploaded.keys():
     
  # Main code (Memprediksi Gambar dari model)
  path = fn
  img = image.load_img(path, target_size=(150,150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
     
  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)

  print(fn)
  if classes[0,0] != 0:
    print('paper')
  elif classes[0,1] != 0:
    print('rock')
  else:
    print('scissors')